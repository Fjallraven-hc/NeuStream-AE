"""
ClockWork 

"""
from dataclasses import dataclass
import copy
import uuid
import json
import time
import multiprocessing
from collections import deque
import numba
#from diffusers import StableDiffusionPipeline,EulerAncestralDiscreteScheduler
from DiT_XL_2_pipe_for_clockwork import DiT_pipe
import torch
import argparse

# profile latency can be simulated by module latency
clip_info = {"1": 0.01258800581563264, "2": 0.01258800581563264, "3": 0.013227543048560619, "4": 0.013585503352805972, "5": 0.013602819945663213, "6": 0.013689555460587144, "7": 0.013803832209669053, "8": 0.014494462753646076, "9": 0.01529775985982269, "10": 0.014548799116164446, "11": 0.014422971452586354, "12": 0.014999916683882475, "13": 0.015558380307629705, "14": 0.015356669737957417, "15": 0.015444180904887616}
unet_info = {"1": 0.025514573475345973, "2": 0.04138726428756491, "3": 0.05458601389965043, "4": 0.07295775772072374, "5": 0.08955291747301818, "6": 0.10232851384487004, "7": 0.12418209509225563, "8": 0.14621983799757435, "9": 0.15895684615336356, "10": 0.1778498865952715, "11": 0.1935110173621215, "12": 0.2210442412579432, "13": 0.24527437469968574, "14": 0.26064503369061276, "15": 0.276078911151737}
vae_info = {"1": 0.03665265885647386, "2": 0.0757878105621785, "3": 0.11239828888792544, "4": 0.14526668936014175, "5": 0.18242476100567728, "6": 0.21567578695248812, "7": 0.24994519969914109, "8": 0.2844186464790255, "9": 0.3217231363989413, "10": 0.357597753056325, "11": 0.39994515643920747, "12": 0.4299777471460402, "13": 0.4745087727438658, "14": 0.508298379695043, "15": 0.5447315105702728}
safety_info = {"1": 0.03504515739623457, "2": 0.038062461744993926, "3": 0.031534295855090023, "4": 0.032584191858768465, "5": 0.03203578807879239, "6": 0.0316439371323213, "7": 0.03221851389389485, "8": 0.03162216558121145, "9": 0.03291168597061187, "10": 0.03147947678808123, "11": 0.03236209659371525, "12": 0.031979250349104406, "13": 0.034732765448279676, "14": 0.03571877004578709, "15": 0.031498771044425666}

DiT_info = {"1": 0.01972036121785641, "2": 0.018571753084659578, "3": 0.019397278666496275, "4": 0.024648231767117976, "5": 0.02942073369771242, "6": 0.0327542197778821, "7": 0.03522938949242234, "8": 0.046610258609056474, "9": 0.050186933171004054, "10": 0.05120321824401617}
# vae_info was generated by latency = 0.01472807396832845 * batch_size + 0.0017586554069015659
vae_info = {'1': 0.016486729375230016, '2': 0.031214803343558466, '3': 0.04594287731188691, '4': 0.060670951280215366, '5': 0.07539902524854382, '6': 0.09012709921687226, '7': 0.10485517318520071, '8': 0.11958324715352917, '9': 0.13431132112185762, '10': 0.14903939509018607, '11': 0.16376746905851453, '12': 0.17849554302684295, '13': 0.1932236169951714, '14': 0.20795169096349986, '15': 0.2226797649318283, '16': 0.23740783890015676, '17': 0.2521359128684852, '18': 0.26686398683681367, '19': 0.2815920608051421, '20': 0.2963201347734706, '21': 0.311048208741799, '22': 0.3257762827101275, '23': 0.3405043566784559, '24': 0.35523243064678434, '25': 0.3699605046151128, '26': 0.38468857858344124, '27': 0.3994166525517697, '28': 0.41414472652009815, '29': 0.42887280048842663, '30': 0.44360087445675506, '31': 0.45832894842508354, '32': 0.47305702239341196, '33': 0.4877850963617404, '34': 0.5025131703300688, '35': 0.5172412442983974, '36': 0.5319693182667258, '37': 0.5466973922350542, '38': 0.5614254662033826, '39': 0.5761535401717112, '40': 0.5908816141400396}

pro = {}
for steps in range(200, 251):
    pro[steps] = {}
    for batch_size in range(1, 11):
        pro[steps][batch_size] = DiT_info[str(batch_size)] * steps + vae_info[str(batch_size)]

@dataclass(frozen=True)
class Strategy:
    steps: int
    batch_size: int
    latest: float

@dataclass(frozen=True)
class Work:
    id: int
    duration: float
    work_begin: float

class WorkerTracker:
    def __init__(self,track_queue,shm):
        self.track_queue = track_queue
        self.work_begin = 0
        self.lag = 0.01
        self.future = 0.001
        self.outstanding = deque()
        self.total_outstanding = 0
        self.shm = shm
    
    #@numba.jit
    def _update(self, id: int, time_of_completion: float):
        if(self.outstanding[0].id == id):
            self.total_outstanding -= self.outstanding[0].duration
            self.work_begin = time_of_completion
            self.outstanding.popleft()
        else:
            for ow in self.outstanding:
                if ow.id == id:
                    self.total_outstanding -= ow.duration
                    self.work_begin += ow.duration
                    self.outstanding.remove(ow)
                    break
        if self.outstanding:
            self.work_begin = max(self.work_begin, self.outstanding[0].work_begin)

    def available(self):
        now = time.time()
        work_begin = self.work_begin
        if self.outstanding and (work_begin+self.outstanding[0].duration + self.lag) < now:
            work_begin = now - self.lag - self.outstanding[0].duration
        return max(work_begin + self.total_outstanding, now + self.future)
    
    def add(self, id, duration, work_begin = 0):
        if not self.outstanding:
            self.work_begin = max(time.time(),self.work_begin)
        self.outstanding.append(Work(id, duration, work_begin))
        self.total_outstanding += duration
        return 0
    
    def success(self,id, time_of_completion):
        self._update(id,time_of_completion)

    def track(self):
        if not self.track_queue.empty():
            item = self.track_queue.get()
            self.success(item["id"],item["time_of_completion"])
        if self.shm[0] == -1:
            self.shm[0] = self.available()             
        if self.shm[1] == -1:
            self.shm[1] = self.add(self.shm[2],self.shm[3])

def worker_tracker(tracker_queue, shm):
    tracker = WorkerTracker(tracker_queue,shm)
    while True:
        tracker.track()

class Controller:
    def __init__(self,request_queue,infer_queue,shared_mem,instance,batchsize):
        self.instance = instance 
        self.batchsize = batchsize 
        self.strategies = []
        self.strategy = { i:[] for i in self.instance}
        self.sd = { i:{ j:deque() for j in self.batchsize }for i in self.instance }
        self.request_queue = request_queue
        self.infer_queue = infer_queue
        self.tracker = shared_mem
        self.schedule_ahead = 0.01
        self.id = 1

    #@numba.jit
    def pull_incoming_requests(self):
        size = self.request_queue.qsize() 
        for _ in range(size):
            item = self.request_queue.get()
            key = item["num-sampling-steps"]
            for b in self.batchsize:
                self.sd[key][b].append(item)
    
    #@numba.jit
    def add_model_strategy(self, instance: int, max_batch_size = None):
        if max_batch_size is None:
            max_batch_size = self.batchsize[-1]
        self.pull_incoming_requests()
        sta = []
        for b in reversed(self.batchsize):
            if len(self.sd[instance][b]) == 0 or b > max_batch_size:
                continue
            if len(self.sd[instance][b]) >= b:
                ddl = self.sd[instance][b][0]["request_time"] + self.sd[instance][b][0]["SLOs"]
                priority = ddl - pro[instance][b] 
                sta.append(Strategy(instance,b, priority))
        self.strategy[instance] = sta
        if not self.strategy[instance]:
            return
        for i in self.strategy[instance]:
            self.strategies.append(i)

    #@numba.jit
    def try_deque(self, free_at: float,instance: int, batch_size: int):
        self.pull_incoming_requests()
        for b in self.batchsize:
            exec_time = pro[instance][b] 
            complete_time = free_at + exec_time
            while(len(self.sd[instance][b]) > 0):
                item = self.sd[instance][b][0]
                if item["request_time"] + item["SLOs"] < complete_time:
                    self.sd[instance][b].popleft()
                else:
                    break
        i = 1
        while(i < len(self.sd[instance]) and len(self.sd[instance][i+1]) >= i+1 ):
            i += 1
        qe = self.sd[instance][i]
        if len(qe) < i or i < batch_size:
            return None
        
        input = []

        for _ in range(i):
            req = qe.popleft()
            input.append(req)
            seqno = req["id"]
        for q in self.sd[instance].values():
            while len(q) > 0 and q[0]["id"] <= seqno:
                q.popleft()
        return input
    
    def schedule_info(self, gpu_id):
        for i in self.instance:
            self.add_model_strategy(i)        
        if not self.strategies:
            return 
        while (self.strategies):
            self.tracker[gpu_id][0] = -1
            while(self.tracker[gpu_id][0] == -1):
                continue
            exe = self.tracker[gpu_id][0]
            self.tracker[gpu_id][0] = 0
            if time.time() + self.schedule_ahead < exe and exe != 0:
                break
            self.strategies.sort(key=lambda x: x.latest,reverse=True)
            strategy = self.strategies.pop()
            instance = strategy.steps
            self.strategies = [x for x in self.strategies if x.steps != instance ]
            self.strategy[instance] = []
            input = self.try_deque(exe, instance, strategy.batch_size)
            if input is None:
                self.add_model_strategy(instance, strategy.batch_size - 1)
            else:
                input[0]["track_id"] = self.id
                duration = pro[instance][len(input)] 
                self.tracker[gpu_id][2] = self.id
                self.tracker[gpu_id][3] = duration
                self.tracker[gpu_id][1] = -1 
                while (self.tracker[gpu_id][1] == -1):
                    continue                             
                self.infer_queue[gpu_id].put(input)
                self.id += 1
                break
        self.strategies = []

def controller_(request_queue,infer_queue,tracker_queue,num_worker,instance,batchsize):
    contr = Controller(request_queue,infer_queue,tracker_queue,instance,batchsize)
    i = 0
    while True:
        contr.schedule_info(i)
        i = (i+1)%num_worker

def infer_worker(infer_queue,pipe,idxx,tracker_queue, log_file):
    f = open(log_file, "w")
    data = {
        "good": 0,
        "finish": 0,
    }
    
    log = False
    #pipe("a girl",num_inference_steps=30)
    #pipe("a girl",num_inference_steps=35)
    pipe([100], 200, 3.0)
    pipe([100], 250, 4.0)
    
    @torch.inference_mode()
    #@numba.jit
    def infer(item, tracker_queue,pipe):
        good = 0
        steps = item[0]["num-sampling-steps"]
        cfg_scale = item[0]["cfg_scale"]
        track_id = item[0]["track_id"]
        batch = len(item)
        class_label_list = []
        for i in item:
            class_label_list.append(i["class_label"])
        #h = item[0]["height"]
        #w=h
        pipe(class_label_list, steps, cfg_scale)
        ed = time.time()
        for i in item:
            if ed <= i["request_time"] + i["SLOs"]:
                good += 1
        tracker_queue.put({"id":track_id,"time_of_completion": time.time()}) 
        sid = ""
        for i in item:
            sid += str(i["id"]) + " "
        return batch, good, sid
    
    while True:
        item = infer_queue.get()
        batch, good_, sid = infer(item, tracker_queue, pipe)
        if not log:
            log = not item[0]["warmup"]
        if log:
            data["good"] += good_
            data["finish"] += batch  
        info = f"{idxx}å·worker ---- good : {data['good']} --- finish: {data['finish']} --- id: {sid} \n"
        f.write(info) 
        f.flush()
        print(info)

if __name__ == "__main__":

    parser = argparse.ArgumentParser(description="parameter for server.")

    parser.add_argument('--image_size', required=True, type=int, help='a value to determine image size')
    parser.add_argument('--rate_scale', required=True, type=str, help='a value to determine arrival rate')
    parser.add_argument('--cv_scale', required=True, type=str, help='a value to determine arrival coefficient of variation')
    parser.add_argument('--slo_scale', required=True, type=float, help='a value to determine slo factor')
    parser.add_argument('--log_folder', required=True, type=str, help='a value to determine log folder')
    parser.add_argument('--run_device', required=True, type=str, help='a value to determine running device')

    torch.multiprocessing.set_start_method("spawn")

    args = parser.parse_args()
    rate = args.rate_scale
    slo_factor = args.slo_scale
    cv = args.cv_scale
    log_folder = args.log_folder
    device = args.run_device

    test_request_count = 500 # 200
    from datetime import datetime, timezone, timedelta
    timestamp = datetime.now(timezone(timedelta(hours=8))).strftime("%Y-%m-%d %H:%M:%S")    
    log_file_path = f"{log_folder}/{timestamp}_Gamma_rate={rate}_cv={cv}_slo_factor={slo_factor}_request={test_request_count}_device=RTX4090_image_size={args.image_size}.log"

    pipes = [        
        DiT_pipe(device),
        # StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16).to("cuda:2"),
        # StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16).to("cuda:4"),
        # StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16).to("cuda:7"),
    ]

    instance = range(200, 251)
    batchsize = range(1,11)    
    num_worker = 1

    infer_queue = [multiprocessing.Queue() for _ in range(num_worker)]
    request_queue = multiprocessing.Queue()
    tracker_queue = [multiprocessing.Queue() for _ in range(num_worker) ]

    shared_mem = [multiprocessing.Array('d',[0,0,0,0]) for _ in range(num_worker)]

    processes = [multiprocessing.Process(target=infer_worker, args=(infer_queue[i],pipes[i],i,tracker_queue[i],log_file_path)) for i in range(num_worker)] + [
        multiprocessing.Process(target=controller_, args=(request_queue,infer_queue,shared_mem,num_worker,instance,batchsize)),
    ] + [multiprocessing.Process(target=worker_tracker,args=(tracker_queue[i],shared_mem[i])) for i in range(num_worker)]

    for p in processes:
        p.start()

    print("Successfully!")
    time.sleep(6)
    print("begin infer.")

    ## warm up
    warm_up_request = {
            "image_size": 256,
            "num-sampling-steps": 250,
            "class_label": 100,
            "cfg_scale": 4.0,
            "uuid": uuid.uuid1(),
            "request_time": time.time(),
            "SLOs": 5,
            "id": -1 ,# for debug
            "warmup": True,
            }
    for idx in range(10):
        time.sleep(0.3)
        temp_request = copy.deepcopy(warm_up_request)
        temp_request["request_time"] = time.time()
        temp_request["id"] = -1 - idx
        request_queue.put(warm_up_request)
    
    # wait for warm-up end
    time.sleep(15)

    gamma_process_trace_rtx4090_256 = json.load(open("DiT_XL_2_256_trace.json"))

    num_sampling_steps_list = gamma_process_trace_rtx4090_256["random_num_sampling_steps"]
    class_label_list = gamma_process_trace_rtx4090_256["random_class_label"]
    arrival_interval_list = gamma_process_trace_rtx4090_256[f"rate={rate},cv={cv}"]
    
    init_request_latency = 0.0015012567086766164

    ## measure
    begin = time.time()    
    for idx in range(test_request_count):
        time.sleep(arrival_interval_list[idx])
        request = {
            "image_size": 256,
            "num-sampling-steps": num_sampling_steps_list[idx],
            "class_label": class_label_list[idx],
            "cfg_scale": 4.0,
            "uuid": uuid.uuid1(),
            "request_time": time.time(),
            "SLOs": slo_factor * (init_request_latency
                                    + DiT_info["1"] * num_sampling_steps_list[idx]
                                    + vae_info["1"]
                                    ),
            "id": idx ,# for debug
            "warmup": False,
        }
        request_queue.put(request)
    
    time.sleep(20)
    for p in processes:
        p.terminate()

    print("end infer.")
    for p in processes:
        p.join()
    print("throughput:", test_request_count / (time.time() - begin))
